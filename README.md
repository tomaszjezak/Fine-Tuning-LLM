# Fine-Tuning-LLM

Project 1: ** Instruct-Tuning LLaMA (Supervised) **

<a href="https://github.com/artidoro/qlora">
  <img src="[https://shields.io/badge/LinkedIn-blue?logo=linkedin&style=for-the-badge](https://opengraph.githubassets.com/ae28b412dd5e59ffe956b15aadc71b1c3073c052e4fc022cdea9124ad8dfd0d9/artidoro/qlora)https://opengraph.githubassets.com/ae28b412dd5e59ffe956b15aadc71b1c3073c052e4fc022cdea9124ad8dfd0d9/artidoro/qlora" alt="qlora"/>
</a>

Instruct-tune the LLaMA recreation by OpenLM Research "Open LLaMA 7b", consisting of 7 billion parameters.
We trained the LLM on the Dolly15k dataset, consisting of 15,000 prompts/answers (some with additional context). 
Training Goal: Make the LLM user-friendly! User is able to talk and get a quality response. Not just the transformer playing "predict the next token".
** Needs some slight revision. My goal is to upload this to HuggingFace, make a front-end. I've worked with lots of models, done lots of research/read lots of papers, finetuned... but haven't made something "end-to-end" until this! Will complete by March 23.

Project 2: ** Fine-Tuning BLOOMZ

<a href="https://github.com/artidoro/qlora">
  <img src="[https://shields.io/badge/LinkedIn-blue?logo=linkedin&style=for-the-badge](https://opengraph.githubassets.com/ae28b412dd5e59ffe956b15aadc71b1c3073c052e4fc022cdea9124ad8dfd0d9/artidoro/qlora)https://opengraph.githubassets.com/ae28b412dd5e59ffe956b15aadc71b1c3073c052e4fc022cdea9124ad8dfd0d9/artidoro/qlora" alt="qlora"/>
</a>
